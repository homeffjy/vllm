+ main sglang
+ '[' 1 -eq 0 ']'
+ check_gpus
++ nvidia-smi --list-gpus
++ wc -l
+ declare -g gpu_count=1
+ [[ 1 -gt 0 ]]
+ echo 'GPU found.'
GPU found.
++ awk '{print $2}'
+++ nvidia-smi --query-gpu=name --format=csv,noheader
++ echo NVIDIA A100-SXM4-40GB
+ declare -g gpu_type=A100-SXM4-40GB
+ echo 'GPU type is A100-SXM4-40GB'
GPU type is A100-SXM4-40GB
+ export CURRENT_LLM_SERVING_ENGINE=sglang
+ CURRENT_LLM_SERVING_ENGINE=sglang
+ export VLLM_SOURCE_CODE_LOC=/home/fjy/vllm
+ VLLM_SOURCE_CODE_LOC=/home/fjy/vllm
+ pip install -U transformers
Defaulting to user installation because normal site-packages is not writeable
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: transformers in /home/fjy/.local/lib/python3.10/site-packages (4.45.2)
Requirement already satisfied: filelock in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (3.15.4)
Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (0.24.0)
Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (24.1)
Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (2024.5.15)
Requirement already satisfied: requests in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (2.32.3)
Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (0.4.3)
Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/fjy/.local/lib/python3.10/site-packages (from transformers) (0.20.1)
Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from transformers) (4.66.4)
Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from requests->transformers) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from requests->transformers) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from requests->transformers) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/vllm/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)
+ df -h
Filesystem                   Size  Used Avail Use% Mounted on
tmpfs                         51G  3.9M   51G   1% /run
efivarfs                     512K  163K  345K  32% /sys/firmware/efi/efivars
/dev/nvme0n1p2               1.8T  933G  807G  54% /
tmpfs                        252G  4.0K  252G   1% /dev/shm
tmpfs                        5.0M  8.0K  5.0M   1% /run/lock
/dev/nvme0n1p1               1.1G  6.2M  1.1G   1% /boot/efi
/dev/mapper/data_vg-data_lv  7.3T  6.9T  427G  95% /data
tmpfs                         51G  128K   51G   1% /run/user/1451800082
tmpfs                         51G   32K   51G   1% /run/user/1451800038
tmpfs                         51G   20K   51G   1% /run/user/1451800031
tmpfs                         51G   20K   51G   1% /run/user/1451800008
tmpfs                         51G   44K   51G   1% /run/user/1451800044
+ ensure_installed wget
+ local cmd=wget
+ which wget
+ ensure_installed curl
+ local cmd=curl
+ which curl
+ ensure_installed jq
+ local cmd=jq
+ which jq
+ cd /home/fjy/vllm/benchmarks
+ declare -g RESULTS_FOLDER=results/
+ mkdir -p results/
+ BENCHMARK_ROOT=/home/fjy/vllm/benchmarks
+ run_serving_tests /home/fjy/vllm/benchmarks/scripts/tests.json
+ local serving_test_file
+ serving_test_file=/home/fjy/vllm/benchmarks/scripts/tests.json
+ jq -c '.[]' /home/fjy/vllm/benchmarks/scripts/tests.json
+ read -r params
++ echo '{"test_name":"qwen7B_tp1_ib","qps_list":[4,8,16,32,"inf"],"common_parameters":{"model":"/data/llm/Qwen2.5-7B-Instruct-copy/","tp":1,"dataset_name":"ib","dataset_path":"/data/ds/InfiniteBench/","num_prompts":10,"port":8000,"reuse_server":false,"ib_input_len_list":[2048,81920]},"vllm_server_parameters":{"disable_log_stats":"","disable_log_requests":"","gpu_memory_utilization":0.9,"max_num_seqs":512,"dtype":"bfloat16"},"vllm_client_parameters":{},"sglang_server_parameters":{"disable_radix_cache":"","enable_torch_compile":"","max_running_request":2560,"dtype":"bfloat16"},"sglang_client_parameters":{}}'
++ jq -r .test_name
+ test_name=qwen7B_tp1_ib
+ [[ -n '' ]]
+ test_name=sglang_qwen7B_tp1_ib
++ echo '{"test_name":"qwen7B_tp1_ib","qps_list":[4,8,16,32,"inf"],"common_parameters":{"model":"/data/llm/Qwen2.5-7B-Instruct-copy/","tp":1,"dataset_name":"ib","dataset_path":"/data/ds/InfiniteBench/","num_prompts":10,"port":8000,"reuse_server":false,"ib_input_len_list":[2048,81920]},"vllm_server_parameters":{"disable_log_stats":"","disable_log_requests":"","gpu_memory_utilization":0.9,"max_num_seqs":512,"dtype":"bfloat16"},"vllm_client_parameters":{},"sglang_server_parameters":{"disable_radix_cache":"","enable_torch_compile":"","max_running_request":2560,"dtype":"bfloat16"},"sglang_client_parameters":{}}'
++ jq -r .common_parameters
+ common_params='{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .model
+ model=/data/llm/Qwen2.5-7B-Instruct-copy/
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .tp
+ tp=1
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .dataset_name
+ dataset_name=ib
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .dataset_path
+ dataset_path=/data/ds/InfiniteBench/
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .port
+ port=8000
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .num_prompts
+ num_prompts=10
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .reuse_server
+ reuse_server=false
++ echo '{
  "model": "/data/llm/Qwen2.5-7B-Instruct-copy/",
  "tp": 1,
  "dataset_name": "ib",
  "dataset_path": "/data/ds/InfiniteBench/",
  "num_prompts": 10,
  "port": 8000,
  "reuse_server": false,
  "ib_input_len_list": [
    2048,
    81920
  ]
}'
++ jq -r .ib_input_len_list
+ ib_input_len_list='[
  2048,
  81920
]'
++ echo '[' 2048, 81920 ']'
++ jq -r '.[]'
+ ib_input_len_list='2048
81920'
++ echo '{"test_name":"qwen7B_tp1_ib","qps_list":[4,8,16,32,"inf"],"common_parameters":{"model":"/data/llm/Qwen2.5-7B-Instruct-copy/","tp":1,"dataset_name":"ib","dataset_path":"/data/ds/InfiniteBench/","num_prompts":10,"port":8000,"reuse_server":false,"ib_input_len_list":[2048,81920]},"vllm_server_parameters":{"disable_log_stats":"","disable_log_requests":"","gpu_memory_utilization":0.9,"max_num_seqs":512,"dtype":"bfloat16"},"vllm_client_parameters":{},"sglang_server_parameters":{"disable_radix_cache":"","enable_torch_compile":"","max_running_request":2560,"dtype":"bfloat16"},"sglang_client_parameters":{}}'
++ jq -r .sglang_server_parameters
+ server_params='{
  "disable_radix_cache": "",
  "enable_torch_compile": "",
  "max_running_request": 2560,
  "dtype": "bfloat16"
}'
++ echo '{"test_name":"qwen7B_tp1_ib","qps_list":[4,8,16,32,"inf"],"common_parameters":{"model":"/data/llm/Qwen2.5-7B-Instruct-copy/","tp":1,"dataset_name":"ib","dataset_path":"/data/ds/InfiniteBench/","num_prompts":10,"port":8000,"reuse_server":false,"ib_input_len_list":[2048,81920]},"vllm_server_parameters":{"disable_log_stats":"","disable_log_requests":"","gpu_memory_utilization":0.9,"max_num_seqs":512,"dtype":"bfloat16"},"vllm_client_parameters":{},"sglang_server_parameters":{"disable_radix_cache":"","enable_torch_compile":"","max_running_request":2560,"dtype":"bfloat16"},"sglang_client_parameters":{}}'
++ jq -r .sglang_client_parameters
+ client_params='{}'
++ json2args '{}'
++ local 'json_string={}'
+++ echo '{}'
+++ jq -r '
      to_entries |
      map("--" + (.key | gsub("_"; "-")) + " " + (.value | tostring)) |
      join(" ")
    '
++ local args=
++ echo ''
+ client_args=
++ echo '{"test_name":"qwen7B_tp1_ib","qps_list":[4,8,16,32,"inf"],"common_parameters":{"model":"/data/llm/Qwen2.5-7B-Instruct-copy/","tp":1,"dataset_name":"ib","dataset_path":"/data/ds/InfiniteBench/","num_prompts":10,"port":8000,"reuse_server":false,"ib_input_len_list":[2048,81920]},"vllm_server_parameters":{"disable_log_stats":"","disable_log_requests":"","gpu_memory_utilization":0.9,"max_num_seqs":512,"dtype":"bfloat16"},"vllm_client_parameters":{},"sglang_server_parameters":{"disable_radix_cache":"","enable_torch_compile":"","max_running_request":2560,"dtype":"bfloat16"},"sglang_client_parameters":{}}'
++ jq -r .qps_list
+ qps_list='[
  4,
  8,
  16,
  32,
  "inf"
]'
++ echo '[
  4,
  8,
  16,
  32,
  "inf"
]'
++ jq -r '.[] | @sh'
+ qps_list='4
8
16
32
'\''inf'\'''
+ echo 'Running over qps list 4
8
16
32
'\''inf'\'''
Running over qps list 4
8
16
32
'inf'
+ [[ 1 -lt 1 ]]
+ [[ false == \t\r\u\e ]]
+ kill_gpu_processes
++ whoami
+ pkill -u fjy -f python
++ whoami
+ pkill -u fjy -f python3
++ whoami
+ pkill -u fjy -f tritonserver
++ whoami
+ pkill -u fjy -f pt_main_thread
++ whoami
+ pkill -u fjy -f text-generation
++ whoami
+ pkill -u fjy -f lmdeploy
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ head -n 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
+ '[' 13561 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13757 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13757 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13757 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13757 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
+ '[' 13757 -ge 1000 ']'
+ sleep 1
++ nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits
++ head -n 1
